{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YsuqTt32AbLJpXHB_gLfNC5FhTFYYv-o",
      "authorship_tag": "ABX9TyM5y5jXrdgaGigIoiEadEOC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msymhkr/mainopen/blob/main/SRGAN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Images to hr and lr"
      ],
      "metadata": {
        "id": "CNH3_YhQ7n5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def resize_and_save_images(input_directory, high_res_directory, low_res_directory):\n",
        "    # Create output directories if they don't exist\n",
        "    os.makedirs(high_res_directory, exist_ok=True)\n",
        "    os.makedirs(low_res_directory, exist_ok=True)\n",
        "\n",
        "    # Loop through all images in the input directory\n",
        "    for filename in os.listdir(input_directory):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Add more formats if necessary\n",
        "            img_path = os.path.join(input_directory, filename)\n",
        "\n",
        "            # Open the image\n",
        "            with Image.open(img_path) as img:\n",
        "                # Resize for high resolution\n",
        "                high_res_img = img.resize((256, 256), Image.Resampling.LANCZOS)\n",
        "                high_res_img.save(os.path.join(high_res_directory, filename))\n",
        "\n",
        "                # Resize for low resolution\n",
        "                low_res_img = img.resize((64, 64), Image.Resampling.LANCZOS)\n",
        "                low_res_img.save(os.path.join(low_res_directory, filename))\n",
        "\n",
        "# Example usage\n",
        "input_directory = '/content/drive/MyDrive/sample_file/srgan_train_samples'\n",
        "high_res_directory = '/content/drive/MyDrive/sample_file/srgan_train_samples/srgan_train_hr'\n",
        "low_res_directory = '/content/drive/MyDrive/sample_file/srgan_train_samples/srgan_train_lr'\n",
        "\n",
        "resize_and_save_images(input_directory, high_res_directory, low_res_directory)"
      ],
      "metadata": {
        "id": "N67VlB3S7l1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Normalize the images"
      ],
      "metadata": {
        "id": "kho7zMHozdVl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ullaxqD1h_cJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(256, 256)):\n",
        "    # Load image\n",
        "    img = load_img(image_path, target_size=target_size)\n",
        "    img_array = img_to_array(img)\n",
        "    # Alternatively, normalize to the range [-1, 1]\n",
        "    # img_array = (img_array / 127.5) - 1.0\n",
        "    # Normalize to the range [0, 1]\n",
        "    img_array = img_array / 255.0\n",
        "    return img_array\n",
        "\n",
        "def load_images_from_directory(directory, target_size=(256, 256)):\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):  # Add more formats if necessary\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            img_array = load_and_preprocess_image(img_path, target_size)\n",
        "            images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "# Assuming you have a directory with images\n",
        "image_directory = '/content/drive/MyDrive/sample_file/srgan_train_samples/srgan_train_hr'\n",
        "normalized_train_images = load_images_from_directory(image_directory)\n",
        "\n",
        "# Now you can use normalized_images for training your SRGAN model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras import Model\n",
        "from keras.layers import Conv2D, PReLU, BatchNormalization, Flatten\n",
        "from keras.layers import UpSampling2D, LeakyReLU, Dense, Input, add\n",
        "\n",
        "lr_ip = Input(shape=(25,25,3))\n",
        "hr_ip = Input(shape=(100,100,3))\n",
        "train_lr, train_hr = normalized_train_images # training images arrays normalized between 0 & 1\n",
        "test_lr, test_hr = # testing images arrays normalized between 0 & 1"
      ],
      "metadata": {
        "id": "hVkUD8aeyVO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Generator"
      ],
      "metadata": {
        "id": "JAlMLt1vBsR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual block\n",
        "def res_block(ip):\n",
        "\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(ip)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "    res_model = PReLU(shared_axes = [1,2])(res_model)\n",
        "\n",
        "    res_model = Conv2D(64, (3,3), padding = \"same\")(res_model)\n",
        "    res_model = BatchNormalization(momentum = 0.5)(res_model)\n",
        "\n",
        "    return add([ip,res_model])\n",
        "\n",
        "# Upscale the image 2x\n",
        "def upscale_block(ip):\n",
        "    up_model = Conv2D(256, (3,3), padding=\"same\")(ip)\n",
        "    up_model = UpSampling2D( size = 2 )(up_model)\n",
        "    up_model = PReLU(shared_axes=[1,2])(up_model)\n",
        "\n",
        "    return up_model\n",
        "num_res_block = 16\n",
        "\n",
        "# Generator Model\n",
        "def create_gen(gen_ip):\n",
        "    layers = Conv2D(64, (9,9), padding=\"same\")(gen_ip)\n",
        "    layers = PReLU(shared_axes=[1,2])(layers)\n",
        "    temp = layers\n",
        "    for i in range(num_res_block):\n",
        "        layers = res_block(layers)\n",
        "    layers = Conv2D(64, (3,3), padding=\"same\")(layers)\n",
        "    layers = BatchNormalization(momentum=0.5)(layers)\n",
        "    layers = add([layers,temp])\n",
        "    layers = upscale_block(layers)\n",
        "    layers = upscale_block(layers)\n",
        "    op = Conv2D(3, (9,9), padding=\"same\")(layers)\n",
        "    return Model(inputs=gen_ip, outputs=op)"
      ],
      "metadata": {
        "id": "wa5_0LURBr2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Discriminator Block"
      ],
      "metadata": {
        "id": "cMKn8UITDfVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Small block inside the discriminator\n",
        "def discriminator_block(ip, filters, strides=1, bn=True):\n",
        "\n",
        "    disc_model = Conv2D(filters, (3,3), strides, padding=\"same\")(ip)\n",
        "    disc_model = LeakyReLU( alpha=0.2 )(disc_model)\n",
        "    if bn:\n",
        "        disc_model = BatchNormalization( momentum=0.8 )(disc_model)\n",
        "    return disc_model\n",
        "\n",
        "# Discriminator Model\n",
        "def create_disc(disc_ip):\n",
        "    df = 64\n",
        "\n",
        "    d1 = discriminator_block(disc_ip, df, bn=False)\n",
        "    d2 = discriminator_block(d1, df, strides=2)\n",
        "    d3 = discriminator_block(d2, df*2)\n",
        "    d4 = discriminator_block(d3, df*2, strides=2)\n",
        "    d5 = discriminator_block(d4, df*4)\n",
        "    d6 = discriminator_block(d5, df*4, strides=2)\n",
        "    d7 = discriminator_block(d6, df*8)\n",
        "    d8 = discriminator_block(d7, df*8, strides=2)\n",
        "\n",
        "    d8_5 = Flatten()(d8)\n",
        "    d9 = Dense(df*16)(d8_5)\n",
        "    d10 = LeakyReLU(alpha=0.2)(d9)\n",
        "    validity = Dense(1, activation='sigmoid')(d10)\n",
        "    return Model(disc_ip, validity)"
      ],
      "metadata": {
        "id": "Ln2GwSFtDlI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG19 Model"
      ],
      "metadata": {
        "id": "gYCRIleESaHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG19\n",
        "# Build the VGG19 model upto 10th layer\n",
        "# Used to extract the features of high res imgaes\n",
        "def build_vgg():\n",
        "    vgg = VGG19(weights=\"imagenet\")\n",
        "    vgg.outputs = [vgg.layers[9].output]\n",
        "    img = Input(shape=hr_shape)\n",
        "    img_features = vgg(img)\n",
        "    return Model(img, img_features)"
      ],
      "metadata": {
        "id": "7O4i37slSiCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combined Model"
      ],
      "metadata": {
        "id": "JmhDJRZBTDau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attach the generator and discriminator\n",
        "def create_comb(gen_model, disc_model, vgg, lr_ip, hr_ip):\n",
        "    gen_img = gen_model(lr_ip)\n",
        "    gen_features = vgg(gen_img)\n",
        "    disc_model.trainable = False\n",
        "    validity = disc_model(gen_img)\n",
        "    return Model([lr_ip, hr_ip],[validity,gen_features])"
      ],
      "metadata": {
        "id": "4vcbXGYGTEZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare models"
      ],
      "metadata": {
        "id": "pwWAPuMaTIjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = create_gen(lr_ip)\n",
        "discriminator = create_disc(hr_ip)\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "  metrics=['accuracy'])\n",
        "vgg = build_vgg()\n",
        "vgg.trainable = False\n",
        "gan_model = create_comb(generator, discriminator, vgg, lr_ip, hr_ip)\n",
        "gan_model.compile(loss=[\"binary_crossentropy\",\"mse\"], loss_weights=\n",
        "  [1e-3, 1], optimizer=\"adam\")"
      ],
      "metadata": {
        "id": "s0EkeJDqTIHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample the training data into small batches"
      ],
      "metadata": {
        "id": "kx8SCEUxTXwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "train_lr_batches = []\n",
        "train_hr_batches = []\n",
        "for it in range(int(train_hr.shape[0] / batch_size)):\n",
        "    start_idx = it * batch_size\n",
        "    end_idx = start_idx + batch_size\n",
        "    train_hr_batches.append(train_hr[start_idx:end_idx])\n",
        "    train_lr_batches.append(train_lr[start_idx:end_idx])\n",
        "train_lr_batches = np.array(train_lr_batches)\n",
        "train_hr_batches = np.array(train_hr_batches)"
      ],
      "metadata": {
        "id": "IQkvaeHQTXZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "c_BPBwtoTrz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for e in range(epochs):\n",
        "    gen_label = np.zeros((batch_size, 1))\n",
        "    real_label = np.ones((batch_size,1))\n",
        "    g_losses = []\n",
        "    d_losses = []\n",
        "    for b in range(len(train_hr_batches)):\n",
        "        lr_imgs = train_lr_batches[b]\n",
        "        hr_imgs = train_hr_batches[b]\n",
        "        gen_imgs = generator.predict_on_batch(lr_imgs)\n",
        "        #Dont forget to make the discriminator trainable\n",
        "        discriminator.trainable = True\n",
        "\n",
        "        #Train the discriminator\n",
        "        d_loss_gen = discriminator.train_on_batch(gen_imgs,\n",
        "          gen_label)\n",
        "        d_loss_real = discriminator.train_on_batch(hr_imgs,\n",
        "          real_label)\n",
        "        discriminator.trainable = False\n",
        "        d_loss = 0.5 * np.add(d_loss_gen, d_loss_real)\n",
        "        image_features = vgg.predict(hr_imgs)\n",
        "\n",
        "        #Train the generator\n",
        "        g_loss, _, _ = gan_model.train_on_batch([lr_imgs, hr_imgs],\n",
        "          [real_label, image_features])\n",
        "\n",
        "        d_losses.append(d_loss)\n",
        "        g_losses.append(g_loss)\n",
        "    g_losses = np.array(g_losses)\n",
        "    d_losses = np.array(d_losses)\n",
        "\n",
        "    g_loss = np.sum(g_losses, axis=0) / len(g_losses)\n",
        "    d_loss = np.sum(d_losses, axis=0) / len(d_losses)\n",
        "    print(\"epoch:\", e+1 ,\"g_loss:\", g_loss, \"d_loss:\", d_loss)"
      ],
      "metadata": {
        "id": "Yj03IkKATrhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "byA7iFcnT8Z7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label = np.ones((len(test_lr),1))\n",
        "test_features = vgg.predict(test_hr)\n",
        "eval,_,_ = gan_model.evaluate([test_lr, test_hr], [label,test_features])"
      ],
      "metadata": {
        "id": "YPfY34cnT8Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict the output"
      ],
      "metadata": {
        "id": "cjLOJMxFUEAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_prediction = generator.predict_on_batch(test_lr)"
      ],
      "metadata": {
        "id": "BkeSNM_3UDuj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}